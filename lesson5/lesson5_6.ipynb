{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1676640c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Ollama 模型設定完成 ***\n",
      "使用模型: gemma3:4b\n",
      "模型類型:<class 'langchain_ollama.llms.OllamaLLM'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"gemma3:4b\")\n",
    "print(\"*** Ollama 模型設定完成 ***\")\n",
    "print(f\"使用模型: gemma3:4b\")\n",
    "print(f\"模型類型:{type(model)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43dfe1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 基本 Prompt Template 範例 ===\n",
      "\n",
      "你是一位專業的繁體中文翻譯家，具有豐富的語言學背景。\n",
      "請將使用者提供的以下英文句子翻譯成流暢、自然的繁體中文。\n",
      "\n",
      "英文句子：Hello, how are you?\n",
      "繁體中文翻譯：\n",
      "\n",
      "\n",
      "==================================================\n",
      "Ollama gemma3:4b 模型回應:\n",
      "你好，你最近好嗎？\n",
      "\n",
      "或者更自然一點：\n",
      "\n",
      "您好，最近過得好嗎？ (如果對方比較正式)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. 基本 Prompt Template 使用\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# 建立翻譯模板\n",
    "template_text = \"\"\"\n",
    "你是一位專業的繁體中文翻譯家，具有豐富的語言學背景。\n",
    "請將使用者提供的以下英文句子翻譯成流暢、自然的繁體中文。\n",
    "\n",
    "英文句子：{english_sentence}\n",
    "繁體中文翻譯：\n",
    "\"\"\"\n",
    "\n",
    "# 建立 Prompt Template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"english_sentence\"],\n",
    "    template=template_text\n",
    ")\n",
    "\n",
    "# 使用模板\n",
    "formatted_prompt = prompt_template.format(english_sentence=\"Hello, how are you?\")\n",
    "print(\"=== 基本 Prompt Template 範例 ===\")\n",
    "print(formatted_prompt)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Ollama gemma3:4b 模型回應:\")\n",
    "\n",
    "response = model.invoke(formatted_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c7086e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 基本 Prompt Template 範例 ===\n",
      "\n",
      "你是一位專業的繁體中文翻譯家，具有豐富的語言學背景。\n",
      "請將使用者提供的以下英文句子翻譯成流暢、自然的繁體中文。\n",
      "\n",
      "英文句子：Despite the initial skepticism from the board, the engineering team persevered with their unconventional approach, which ultimately proved to be the breakthrough the company desperately needed.\n",
      "繁體中文翻譯：\n",
      "\n",
      "\n",
      "==================================================\n",
      "Ollama gemma3:4b 模型回應:\n",
      "儘管董事會最初對他們的非傳統方法持懷疑態度，工程團隊依然堅持下去，最終證明了這一方法正是公司 desperately 需要的突破口。\n",
      "\n",
      "**備註：**\n",
      "\n",
      "*   我盡可能保留了原文的語氣，用「desperately」保留其強調的意味。\n",
      "*   “突破口” 比直接翻譯成“breakthrough”更符合中文表達習慣。\n",
      "*   我使用了“依然堅持下去” 來更自然地表達“persevered with”的意涵。\n",
      "\n",
      "希望這個翻譯符合您的要求！  如果您有任何其他需要翻譯的句子，請隨時提出。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. 基本 Prompt Template 使用\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"gemma3:4b\")\n",
    "\n",
    "# 建立翻譯模板\n",
    "template_text = \"\"\"\n",
    "你是一位專業的繁體中文翻譯家，具有豐富的語言學背景。\n",
    "請將使用者提供的以下英文句子翻譯成流暢、自然的繁體中文。\n",
    "\n",
    "英文句子：{english_sentence}\n",
    "繁體中文翻譯：\n",
    "\"\"\"\n",
    "\n",
    "# 建立 Prompt Template\n",
    "prompt_template = PromptTemplate(\n",
    "    template=template_text,\n",
    "    input_variables=[\"english_sentence\"]\n",
    "    \n",
    ")\n",
    "\n",
    "# 使用模板\n",
    "formatted_prompt = prompt_template.format(english_sentence=\"Despite the initial skepticism from the board, the engineering team persevered with their unconventional approach, which ultimately proved to be the breakthrough the company desperately needed.\")\n",
    "print(\"=== 基本 Prompt Template 範例 ===\")\n",
    "print(formatted_prompt)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Ollama gemma3:4b 模型回應:\")\n",
    "\n",
    "response = model.invoke(formatted_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ee7d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 多變數複雜模板範例 ===\n",
      "Human: \n",
      "你是一位專業的繁體中文翻譯家，專精於商業領域。\n",
      "請將以下英文文本翻譯成繁體中文，並確保：\n",
      "1. 保持原文的語氣和風格\n",
      "2. 使用專業術語\n",
      "3. 符合繁體中文的語言習慣\n",
      "\n",
      "英文文本：The quarterly revenue increased by 15% compared to last year.\n",
      "繁體中文翻譯：\n",
      "\n",
      "\n",
      "==================================================\n",
      "Ollama gemma3:4b 模型回應:\n",
      "**選項一（更正式，適合商業報告）：**\n",
      "\n",
      "本季營收較去年同期增長百分之十五。\n",
      "\n",
      "**選項二（稍口語，適合內部溝通）：**\n",
      "\n",
      "本季營收成長了百分之十五，相較去年同期明顯提升。\n",
      "\n",
      "**選項三（強調數字，適合數據彙總）：**\n",
      "\n",
      "本季營收增長幅度為百分之十五，與去年同期相比呈現顯著成長。\n",
      "\n",
      "**選擇理由：**\n",
      "\n",
      "*   **“營收”** 是商業領域中用於描述收入的標準術語。\n",
      "*   **“本季”** 和 **“去年同期”** 都是常用的時間比較方式。\n",
      "*   我選擇了多個選項，以便您根據實際使用場景選擇最合適的表達方式。\n",
      "\n",
      "我會根據您提供的更多上下文，提供更精確的翻譯。 如果您需要針對特定行業或領域進行翻譯，請提供更多信息。\n"
     ]
    }
   ],
   "source": [
    "# 2. 多變數的複雜模板\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"gemma3:4b\")\n",
    "\n",
    "# 建立多變數的翻譯模板\n",
    "complex_template = \"\"\"\n",
    "你是一位專業的{target_language}翻譯家，專精於{domain}領域。\n",
    "請將以下{source_language}文本翻譯成{target_language}，並確保：\n",
    "1. 保持原文的語氣和風格\n",
    "2. 使用專業術語\n",
    "3. 符合{target_language}的語言習慣\n",
    "\n",
    "{source_language}文本：{text}\n",
    "{target_language}翻譯：\n",
    "\"\"\"\n",
    "\n",
    "# 建立 ChatPromptTemplate\n",
    "chat_prompt_template = ChatPromptTemplate.from_template(complex_template)\n",
    "\n",
    "# 使用多個變數\n",
    "formatted_prompt = chat_prompt_template.format(\n",
    "    source_language=\"英文\",\n",
    "    target_language=\"繁體中文\", \n",
    "    domain=\"商業\",\n",
    "    text=\"The quarterly revenue increased by 15% compared to last year.\"\n",
    ")\n",
    "\n",
    "response = model.invoke(formatted_prompt)\n",
    "\n",
    "print(\"=== 多變數複雜模板範例 ===\")\n",
    "print(formatted_prompt)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Ollama gemma3:4b 模型回應:\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
