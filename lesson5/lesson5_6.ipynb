{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1676640c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Ollama 模型設定完成 ***\n",
      "使用模型: gemma3:4b\n",
      "模型類型:<class 'langchain_ollama.llms.OllamaLLM'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"gemma3:4b\")\n",
    "print(\"*** Ollama 模型設定完成 ***\")\n",
    "print(f\"使用模型: gemma3:4b\")\n",
    "print(f\"模型類型:{type(model)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43dfe1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 基本 Prompt Template 範例 ===\n",
      "\n",
      "你是一位專業的繁體中文翻譯家，具有豐富的語言學背景。\n",
      "請將使用者提供的以下英文句子翻譯成流暢、自然的繁體中文。\n",
      "\n",
      "英文句子：Hello, how are you?\n",
      "繁體中文翻譯：\n",
      "\n",
      "\n",
      "==================================================\n",
      "Ollama gemma3:4b 模型回應:\n",
      "你好，你最近好嗎？\n",
      "\n",
      "或者更自然一點：\n",
      "\n",
      "您好，最近過得好嗎？ (如果對方比較正式)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. 基本 Prompt Template 使用\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# 建立翻譯模板\n",
    "template_text = \"\"\"\n",
    "你是一位專業的繁體中文翻譯家，具有豐富的語言學背景。\n",
    "請將使用者提供的以下英文句子翻譯成流暢、自然的繁體中文。\n",
    "\n",
    "英文句子：{english_sentence}\n",
    "繁體中文翻譯：\n",
    "\"\"\"\n",
    "\n",
    "# 建立 Prompt Template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"english_sentence\"],\n",
    "    template=template_text\n",
    ")\n",
    "\n",
    "# 使用模板\n",
    "formatted_prompt = prompt_template.format(english_sentence=\"Hello, how are you?\")\n",
    "print(\"=== 基本 Prompt Template 範例 ===\")\n",
    "print(formatted_prompt)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Ollama gemma3:4b 模型回應:\")\n",
    "\n",
    "response = model.invoke(formatted_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c7086e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 基本 Prompt Template 範例 ===\n",
      "\n",
      "你是一位專業的繁體中文翻譯家，具有豐富的語言學背景。\n",
      "請將使用者提供的以下英文句子翻譯成流暢、自然的繁體中文。\n",
      "\n",
      "英文句子：Despite the initial skepticism from the board, the engineering team persevered with their unconventional approach, which ultimately proved to be the breakthrough the company desperately needed.\n",
      "繁體中文翻譯：\n",
      "\n",
      "\n",
      "==================================================\n",
      "Ollama gemma3:4b 模型回應:\n",
      "儘管董事會最初對他們的非傳統方法持懷疑態度，工程團隊依然堅持下去，最終證明了這一方法正是公司 desperately 需要的突破口。\n",
      "\n",
      "**備註：**\n",
      "\n",
      "*   我盡可能保留了原文的語氣，用「desperately」保留其強調的意味。\n",
      "*   “突破口” 比直接翻譯成“breakthrough”更符合中文表達習慣。\n",
      "*   我使用了“依然堅持下去” 來更自然地表達“persevered with”的意涵。\n",
      "\n",
      "希望這個翻譯符合您的要求！  如果您有任何其他需要翻譯的句子，請隨時提出。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. 基本 Prompt Template 使用\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"gemma3:4b\")\n",
    "\n",
    "# 建立翻譯模板\n",
    "template_text = \"\"\"\n",
    "你是一位專業的繁體中文翻譯家，具有豐富的語言學背景。\n",
    "請將使用者提供的以下英文句子翻譯成流暢、自然的繁體中文。\n",
    "\n",
    "英文句子：{english_sentence}\n",
    "繁體中文翻譯：\n",
    "\"\"\"\n",
    "\n",
    "# 建立 Prompt Template\n",
    "prompt_template = PromptTemplate(\n",
    "    template=template_text,\n",
    "    input_variables=[\"english_sentence\"]\n",
    "    \n",
    ")\n",
    "\n",
    "# 使用模板\n",
    "formatted_prompt = prompt_template.format(english_sentence=\"Despite the initial skepticism from the board, the engineering team persevered with their unconventional approach, which ultimately proved to be the breakthrough the company desperately needed.\")\n",
    "print(\"=== 基本 Prompt Template 範例 ===\")\n",
    "print(formatted_prompt)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Ollama gemma3:4b 模型回應:\")\n",
    "\n",
    "response = model.invoke(formatted_prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
